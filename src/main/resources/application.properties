spring.application.name=llmcpp-chat-demo
llamacpp.prompt.path=${LLAMACPP_PROMPT_PATH:llamacpp_prompt.txt}
llamacpp.temperature=${LLAMACPP_TEMPERATURE:0.2}
llamacpp.topp=${LLAMACPP_TOPP:10}
llamacpp.model=${LLAMACPP_MODEL:tinyllama-1.1b-chat-v1.0.Q6_K.gguf}
llamacpp.thread.cpu=${LLAMACPP_THREAD_CPU:1}
llamacpp.number.context=${LLAMACPP_N_CTX:0}

logging.level.root=OFF

